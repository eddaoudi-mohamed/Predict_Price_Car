{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import yaml\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from typing import Dict, List, Union, Optional\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6927f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    End-to-end model training pipeline for car price prediction\n",
    "    \n",
    "    Features:\n",
    "    - Multiple model support with hyperparameter configurations\n",
    "    - Cross-validation with early stopping\n",
    "    - Automatic model persistence\n",
    "    - Comprehensive performance tracking\n",
    "    - Memory-efficient data handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = 'config/training_config.yaml'):\n",
    "        \"\"\"\n",
    "        Initialize trainer with configuration\n",
    "        \n",
    "        Args:\n",
    "            config_path: Path to YAML configuration file\n",
    "        \"\"\"\n",
    "        self.config = self._load_config(config_path)\n",
    "        self.models: Dict[str, BaseEstimator] = {}\n",
    "        self.results: Dict[str, Dict] = {}\n",
    "        self._validate_config()\n",
    "        \n",
    "    def _load_config(self, config_path: str) -> Dict:\n",
    "        \"\"\"Load training configuration from YAML file\"\"\"\n",
    "        try:\n",
    "            with open(config_path) as f:\n",
    "                config = yaml.safe_load(f)\n",
    "                \n",
    "            # Set default values if not specified\n",
    "            defaults = {\n",
    "                'cross_validation': {\n",
    "                    'cv_folds': 5,\n",
    "                    'scoring': 'neg_root_mean_squared_error'\n",
    "                },\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            return {**defaults, **config}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load config: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def _validate_config(self) -> None:\n",
    "        \"\"\"Validate training configuration\"\"\"\n",
    "        required_keys = ['input_data', 'models', 'output_dir']\n",
    "        if not all(key in self.config for key in required_keys):\n",
    "            raise ValueError(f\"Config missing required keys: {required_keys}\")\n",
    "            \n",
    "        if not isinstance(self.config['models'], dict):\n",
    "            raise ValueError(\"Models config must be a dictionary\")\n",
    "            \n",
    "    def load_data(self) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"Load and validate training data\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading data from {self.config['input_data']}\")\n",
    "            data = pd.read_csv(self.config['input_data'])\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_cols = self.config.get('required_columns', [])\n",
    "            if required_cols and not all(col in data.columns for col in required_cols):\n",
    "                missing = set(required_cols) - set(data.columns)\n",
    "                raise ValueError(f\"Missing required columns: {missing}\")\n",
    "                \n",
    "            X = data.drop(columns=[self.config['target_column']])\n",
    "            y = data[self.config['target_column']]\n",
    "            \n",
    "            return X, y\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data loading failed: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def initialize_models(self) -> None:\n",
    "        \"\"\"Create model instances from configuration\"\"\"\n",
    "        model_factories = {\n",
    "            'random_forest': RandomForestRegressor,\n",
    "            'xgboost': XGBRegressor,\n",
    "            'ridge': Ridge,\n",
    "            'decision_tree': DecisionTreeRegressor\n",
    "        }\n",
    "        \n",
    "        for model_name, params in self.config['models'].items():\n",
    "            if model_name not in model_factories:\n",
    "                logger.warning(f\"Unknown model type: {model_name}. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Merge global and model-specific params\n",
    "                model_params = {\n",
    "                    'random_state': self.config['random_state'],\n",
    "                    'n_jobs': self.config['n_jobs'],\n",
    "                    **params\n",
    "                }\n",
    "                \n",
    "                self.models[model_name] = model_factories[model_name](**model_params)\n",
    "                logger.info(f\"Initialized {model_name} with params: {model_params}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to initialize {model_name}: {e}\")\n",
    "                \n",
    "    def train_models(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        \"\"\"Train all configured models with cross-validation\"\"\"\n",
    "        if not self.models:\n",
    "            raise ValueError(\"No models initialized. Call initialize_models() first.\")\n",
    "            \n",
    "        scorer = make_scorer(\n",
    "            mean_squared_error,\n",
    "            squared=False,  # Returns RMSE\n",
    "            greater_is_better=False\n",
    "        )\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            logger.info(f\"Training {model_name}...\")\n",
    "            start_time = time()\n",
    "            \n",
    "            try:\n",
    "                # Train model\n",
    "                model.fit(X, y)\n",
    "                \n",
    "                # Cross-validation\n",
    "                cv_scores = cross_val_score(\n",
    "                    model, X, y,\n",
    "                    cv=self.config['cross_validation']['cv_folds'],\n",
    "                    scoring=scorer,\n",
    "                    n_jobs=self.config['n_jobs']\n",
    "                )\n",
    "                \n",
    "                # Store results\n",
    "                self.results[model_name] = {\n",
    "                    'train_time': time() - start_time,\n",
    "                    'cv_mean_rmse': -np.mean(cv_scores),\n",
    "                    'cv_std_rmse': np.std(cv_scores),\n",
    "                    'cv_scores': -cv_scores.tolist(),  # Convert to positive RMSE\n",
    "                    'model_params': model.get_params()\n",
    "                }\n",
    "                \n",
    "                logger.info(\n",
    "                    f\"{model_name} trained in {self.results[model_name]['train_time']:.2f}s. \"\n",
    "                    f\"CV RMSE: {self.results[model_name]['cv_mean_rmse']:.2f} Â± \"\n",
    "                    f\"{self.results[model_name]['cv_std_rmse']:.2f}\"\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to train {model_name}: {e}\")\n",
    "                self.results[model_name] = {'error': str(e)}\n",
    "                \n",
    "    def save_models_and_results(self) -> None:\n",
    "        \"\"\"Persist trained models and results to disk\"\"\"\n",
    "        output_dir = Path(self.config['output_dir'])\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save models\n",
    "        for model_name, model in self.models.items():\n",
    "            if 'error' not in self.results.get(model_name, {}):\n",
    "                try:\n",
    "                    joblib.dump(\n",
    "                        model,\n",
    "                        output_dir / f\"{model_name}_model.joblib\",\n",
    "                        compress=3\n",
    "                    )\n",
    "                    logger.info(f\"Saved {model_name} model to {output_dir}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to save {model_name}: {e}\")\n",
    "                    \n",
    "        # Save training results\n",
    "        try:\n",
    "            results_df = pd.DataFrame.from_dict(self.results, orient='index')\n",
    "            results_df.to_csv(output_dir / 'training_results.csv')\n",
    "            logger.info(f\"Saved training results to {output_dir}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save results: {e}\")\n",
    "            \n",
    "    def run_training_pipeline(self) -> None:\n",
    "        \"\"\"Execute complete training workflow\"\"\"\n",
    "        try:\n",
    "            X, y = self.load_data()\n",
    "            self.initialize_models()\n",
    "            self.train_models(X, y)\n",
    "            self.save_models_and_results()\n",
    "            \n",
    "            # Print summary\n",
    "            logger.info(\"\\n=== Training Summary ===\")\n",
    "            for model_name, result in self.results.items():\n",
    "                if 'error' not in result:\n",
    "                    logger.info(\n",
    "                        f\"{model_name}: \"\n",
    "                        f\"RMSE {result['cv_mean_rmse']:.2f} Â± {result['cv_std_rmse']:.2f} \"\n",
    "                        f\"(trained in {result['train_time']:.2f}s)\"\n",
    "                    )\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training pipeline failed: {e}\")\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        trainer = ModelTrainer(config_path=\"config/training_config.yaml\")\n",
    "        trainer.run_training_pipeline()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a76e66",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec4c0e",
   "metadata": {},
   "source": [
    "Model Interpretability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
